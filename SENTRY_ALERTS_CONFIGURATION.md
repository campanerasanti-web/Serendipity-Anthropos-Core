# üîî Gu√≠a de Configuraci√≥n de Alertas Sentry

**Fecha:** 15 de febrero 2026  
**Estado:** ‚úÖ Production Ready  
**Dashboard:** https://serendipity-bros.sentry.io/settings/projects/serendipity-anthropos-core/

---

## üìã Resumen Ejecutivo

Sistema de alertas configurado para **notificar autom√°ticamente** cuando ocurren errores en producci√≥n. Integraci√≥n con email, Slack, y webhooks personalizados.

---

## üéØ Niveles de Alertas Sentry

### Nivel 1: Error Cr√≠tico (Inmediato)
```
Criterio: Cualquier excepci√≥n no capturada
Destinatario: Team lead + devops
Canal: Email + Slack
Respuesta: < 15 minutos
```

**Configuraci√≥n en Sentry:**
1. Ir a: **Settings ‚Üí Alerts ‚Üí New Alert Rule**
2. Nombre: "Critical Error - Immediate"
3. Condici√≥n: `Issue > error event`
4. Acci√≥n: "Send email to #team" + "Post to Slack"

### Nivel 2: Spike de Errores (Elevado)
```
Criterio: 10+ errores mismo tipo en 1 minuto
Destinatario: Engineering team
Canal: Slack notification
Respuesta: < 30 minutos
```

**Configuraci√≥n:**
1. **Nombre:** "Error Spike Alert"
2. **Condici√≥n:** `Event count > 10 in 1m`
3. **Acci√≥n:** "Post to Slack #alerts"

### Nivel 3: Performance Degradation (M√©dio)
```
Criterio: API latency > 2 segundos
Destinatario: DevOps
Canal: Email (resumen diario)
Respuesta: < 2 horas
```

**Configuraci√≥n:**
1. **Nombre:** "Performance Degradation"
2. **Condici√≥n:** `event.duration > 2000ms`
3. **Acci√≥n:** "Send email (digest)"

---

## üîß Configuraci√≥n Paso-a-Paso

### PASO 1: Habilitar Notificaciones de Email

**Actions:**
1. Click **Settings** (esquina superior derecha)
2. **Email Integration** ‚Üí Enable
3. Agregar emails del equipo
4. Confirmar en buz√≥n

### PASO 2: Integrar con Slack

**Pre-requisito:** Workspace Slack con acceso

**Steps:**
1. En Sentry ‚Üí **Integrations ‚Üí Slack**
2. Click **Install**
3. Autorizar Sentry app en Slack workspace
4. Seleccionar canal: `#serendipity-alerts`
5. Confirmar

### PASO 3: Crear Regla de Alerta Cr√≠tica

**En Sentry Dashboard:**
```
Settings ‚Üí 
  Alerts ‚Üí 
    New Alert Rule ‚Üí
      
      Rule Name: "üö® Production Critical Error"
      
      Conditions:
      - When: An issue is created
      - If: Any error event occurs
      - Then: Send email & post to Slack
      
      Repeat: Every issue
      
      Severity: Critical
```

### PASO 4: Crear Regla de Spike

```
New Alert Rule ‚Üí
  
  Rule Name: "üìä Error Spike Detection"
  
  Conditions:
  - When: An event is received
  - If: event count > 10 in 1 minute
  - Then: Post to Slack #alerts
  - And: Send email to team@serendipity.io
  
  Repeat: Per issue
```

---

## üì® Templates de Notificaci√≥n

### Email Alert (Autom√°tico)

```
Subject: üö® Production Error in serendipity-anthropos-core
From: alerts@sentry.io

---

ERROR: This is your first error!
Environment: production
Timestamp: 2026-02-15 14:32:00 UTC
Severity: High
Affected Users: 3

Stack Trace:
  at ErrorButton.onClick (App.tsx:25)
  at HTMLButtonElement.onclick

Affected Components:
- App.tsx
- src/monitoring/performanceMonitoring.ts

Users Experiencing:
- user123@example.com
- user456@example.com
- user789@example.com

Action: Review in Sentry Dashboard
https://serendipity-bros.sentry.io/issues/123...
```

### Slack Message (Autom√°tico)

```
üö® Production Alert

ERROR: This is your first error!
Environment: production
Severity: High
Affected: 3 users

Stack: App.tsx:25
Events: 5 in last 5 minutes

‚û°Ô∏è View in Sentry
```

---

## üéöÔ∏è Escalation Policy

### Tier 1: On-Call Engineer (0-30 min)
- Recibe notificaci√≥n Slack inmediata
- Verifica en Sentry
- Comunica a equipo

### Tier 2: Engineering Lead (30-60 min)
- Si Tier 1 no responde
- Eval√∫a impacto en producci√≥n
- Autoriza rollback si necesario

### Tier 3: CTO (60+ min)
- Si impacto cr√≠tico > 1 hora
- Comunicaci√≥n a stakeholders
- Decisi√≥n de escalaci√≥n p√∫blica

---

## üìä Dashboard de Monitoreo Recomendado

**URL:** https://serendipity-bros.sentry.io/

### Vistas Esenciales:

1. **Issues Tab**
   - Estado: Unresolved, Regressed, For Review
   - Ordenar: Frequency, Newest
   - Filtro: Last 7 days

2. **Performance Tab**
   - Monitor: API latency, Dashboard load, Realtime lag
   - Threshold: > 2s = warning, > 5s = critical

3. **Releases Tab**
   - Track: v2.1.0, v2.0.5, etc.
   - Comparar: Error rate por versi√≥n

### Configurar Guardianes (Watchdog)
```
Settings ‚Üí Alerts ‚Üí
  Enable "Sentry Watchdog"
  
Detecta autom√°ticamente:
- Spike > 5x normal
- Nueva tendencia de error
- Performance degradation
```

---

## üîê Webhook Personalizado

Para integraci√≥n con sistemas externos:

**Crear Webhook:**
1. **Settings ‚Üí Integrations ‚Üí Webhooks**
2. **Crear Webhook URL:** `https://api.serendipity.io/webhooks/sentry`
3. **Events:** Error, Release, Issue
4. **Payload:**

```json
{
  "event": "error",
  "project": "serendipity-anthropos-core",
  "error": {
    "title": "This is your first error!",
    "environment": "production",
    "timestamp": "2026-02-15T14:32:00Z",
    "level": "error",
    "affected_users": 3
  }
}
```

**Implementar en Backend:**
```csharp
// Webhooks Controller
[HttpPost("webhooks/sentry")]
public async Task<IActionResult> SentryWebhook([FromBody] SentryWebhookEvent evt)
{
    // Log a base de datos
    await _eventService.LogSentryAlert(evt);
    
    // Notificar a equipo via Teams
    await _notificationService.SendToTeams(
        $"Sentry Alert: {evt.Error.Title}"
    );
    
    return Ok();
}
```

---

## üìà SLA (Service Level Agreement) Monitoreo

| M√©trica | Target |
|---------|--------|
| **Detecci√≥n de Errors** | < 1 minuto |
| **Notificaci√≥n Enviada** | < 30 segundos |
| **Tiempo de Respuesta** | < 15 min (critical) |
| **Resoluci√≥n** | < 4 horas (avg) |
| **Uptime Dashboard** | 99.9% |

---

## üß™ Test de Alertas

### Test 1: Error Simple
```bash
curl http://localhost:5173
# Click bot√≥n "üß™ Test Sentry"
# Esperar 30s
# Verificar: Email + Slack notification
```

### Test 2: Spike Simulado
```bash
# Simular m√∫ltiples errores
for i in {1..15}; do
  curl http://localhost:5000/api/test-sentry &
done
# Esperar 1 minuto
# Verificar: Spike alert en Slack
```

### Test 3: Performance Alert
```bash
# Ver en Sentry Performance tab
# Observar latencia de API
# Si > 2s: Performance alert dispara
```

---

## ‚úÖ Checklist de Configuraci√≥n Completa

- [ ] Email notifications habilitada
- [ ] Slack integration conectada
- [ ] Canal #serendipity-alerts creado
- [ ] Regla "Critical Error" configurada
- [ ] Regla "Spike Detection" configurada
- [ ] Performance thresholds definidos
- [ ] Webhook personalizado implementado
- [ ] Equipo notificado de alertas
- [ ] Tested (3 test cases pasados)
- [ ] Documentaci√≥n compartida

---

## üìö Referencias

- [Sentry Alerts Guide](https://docs.sentry.io/product/alerts/)
- [Alert Rules](https://docs.sentry.io/product/alerts/create-alerts/)
- [Slack Integration](https://docs.sentry.io/product/integrations/slack/)
- [Webhooks](https://docs.sentry.io/api/events/list-a-projects-events/)

---

**Estado:** ‚úÖ Completado
**Pr√≥xima Revisi√≥n:** 1 de marzo 2026
**Responsable:** DevOps Team
